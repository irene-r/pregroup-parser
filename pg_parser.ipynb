{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pg_parser.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMHa3qmz/LQX1NX0uzd7Nmr"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "gv-2jPu8L2qR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "#FUNCTIONS TO MANIPULATE NESTED LISTS\n",
        "\n",
        "#flatten nested list\n",
        "def flatten(x):                   \n",
        "  y=[]\n",
        "  for t in x:\n",
        "    y=y+t\n",
        "  return y\n",
        "\n",
        "#record positions in nested list. Returns list of tuples (t,k,j) t:type, k:word, j:positions within word \n",
        "def positions(string):             \n",
        "  positions_string=[0]*len(string) \n",
        "  k=0\n",
        "  while k<len(string):\n",
        "    l=len(string[k])\n",
        "    p_s=[0]*l\n",
        "    j=0\n",
        "    while j<l:     \n",
        "      p_s[j]=(string[k][j],k,j)\n",
        "      j=j+1\n",
        "    positions_string[k]=p_s\n",
        "    k=k+1\n",
        "  return positions_string\n",
        "\n",
        "#pop and top function of np.array\n",
        "def np_pop(array):\n",
        "     array=array.tolist()\n",
        "     p=array.pop()\n",
        "     array=np.array(array)\n",
        "     return [array,p]\n",
        "\n",
        "def np_top(array):\n",
        "     array=array.tolist()\n",
        "     array.reverse()\n",
        "     array.pop()\n",
        "     array.reverse()\n",
        "     array=np.array(array)\n",
        "     return array\n",
        "\n",
        "#top function of list : removes first element \n",
        "def top(list1):\n",
        "     list1.reverse()\n",
        "     list1.pop()\n",
        "     list1.reverse()\n",
        "     return list1\n",
        "     \n",
        "#extracts a column from a nested list or list of tuples. returns a list\n",
        "def column(list1,k):\n",
        "     list1=np.array(list1)\n",
        "     col_k = list1[:,k].tolist()\n",
        "     return col_k\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LFoC0foVQRL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#PARSING FUNCTIONS\n",
        "def right_inv(x,y):\n",
        "     if y==x+'^r':\n",
        "       return True \n",
        "     else:\n",
        "       return False\n",
        "     \n",
        "def left_inv(x,y):\n",
        "     if x==y+'^l':\n",
        "       return True\n",
        "     else:\n",
        "       return False\n",
        "\n",
        "def check_reduction(x,y):\n",
        "     if left_inv(x,y)==True or right_inv(x,y)==True:\n",
        "       return True\n",
        "     else:\n",
        "       return False \n",
        "\n",
        "\n",
        "def reduce(word1,wordt):     #lazy parsing \n",
        "         k=0\n",
        "         word2=wordt[:]\n",
        "         while k<len(wordt) and len(word1)>0:\n",
        "            t_prec = word1[-1]\n",
        "            t=word2[k]\n",
        "            C=check_reduction(t_prec,t)\n",
        "            if C==True:\n",
        "               word1.pop()\n",
        "               word2=top(word2)\n",
        "               k=k+1\n",
        "            else:\n",
        "               k=k+1\n",
        "            return word1+word2\n",
        "\n",
        "\n",
        "#picks the left inverse of a given reduced type, from the reduction stack\n",
        "def left_inverse(reductions,r):            \n",
        "            red_flat=flatten(reductions)\n",
        "            k=red_flat.index(r)\n",
        "            left_inv=red_flat[k-1]\n",
        "            return left_inv\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#check if T is a critical type. If so it returns the matching reduction, else it returns T\n",
        "def find_critical(right_reductions, T):\n",
        "      if len(right_reductions)>0:\n",
        "         right_reductions.reverse()\n",
        "         for r in right_reductions:\n",
        "             C=check_reduction(r[0],T[0])\n",
        "             if C==False:\n",
        "                if right_reductions.index(r)==len(right_reductions)-1:\n",
        "                   return T\n",
        "                else:\n",
        "                   continue\n",
        "             else:\n",
        "                return r\n",
        "                break\n",
        "         right_reductions.reverse()  \n",
        "      else:\n",
        "         return T  \n",
        "\n",
        "\n",
        "#resolves criticality: returns True if we accept the criticality, False if we ignore it \n",
        "def decide_critical(string,R,Rc,T):  \n",
        "       flat_pos=flatten(positions(string))\n",
        "       k=flat_pos.index(T)\n",
        "       left_r= left_inverse(R,Rc)\n",
        "       x=left_r[0]\n",
        "       y=Rc[0]\n",
        "       string_flat=flatten(string)\n",
        "       string_k=string_flat[k:]\n",
        "       c_x=[t for t in string_k if t==x]\n",
        "       c_y=[t for t in string_k if t==y]\n",
        "       count_x=len(c_x)+1\n",
        "       count_y=len(c_y)\n",
        "       if count_y>=count_x:\n",
        "         \n",
        "         return True\n",
        "       else: \n",
        "         return False\n",
        "\n",
        "\n",
        "\n",
        "#modifies reduction stack (in case of accepted criticality)\n",
        "def amend_reduction(p0,R,R_stack, Rc, T):\n",
        "                       left_r=left_inverse(R,Rc)\n",
        "                       R_stack.remove(Rc)   \n",
        "                       R_stack=R_stack+[T]\n",
        "                       R.remove([left_r,Rc])\n",
        "                       R=R+[[Rc,T]]\n",
        "                       p0=p0+[left_r]            \n",
        "                       return [p0,R,R_stack]\n",
        "\n",
        "#tests parsing relative to a given type\n",
        "def test(reductions,test_type, c_type):\n",
        "      test=reduce(reductions,test_type)\n",
        "      if test==[]:\n",
        "        print('parsed correctly to type',c_type )\n",
        "        \n",
        "      else:\n",
        "        print('NOT parsed to type',c_type, 'leftover types:', reductions)\n",
        "      return reductions\n",
        "\n",
        "#parsing algorithm \n",
        "            \n",
        "def parse(dict, sentence):\n",
        "     string=[list(random.choice(tuple(dict[x]))) for x in sentence] \n",
        "     print('sentence:',sentence)\n",
        "     print('grammatical types:',string)\n",
        "     print('parsing:')\n",
        "     p0=[]\n",
        "     R=[]\n",
        "     R_stack=[]\n",
        "     pos = positions(string)\n",
        "     p0=p0+pos[0]    \n",
        "     print('processed string:',sentence[0])\n",
        "     k=1\n",
        "     print('reductions:', [])\n",
        "     print('reduced stack',column(p0,0))\n",
        "     while k<len(pos):       \n",
        "       p=pos[k]\n",
        "       p1=p[:]\n",
        "       print('processed string:',sentence[0:k+1])\n",
        "       \n",
        "       for T in p: \n",
        "           t=T[0]\n",
        "           print('processed type:',T)\n",
        "           if len(p0)>0:        \n",
        "               t_prec=p0[-1][0]\n",
        "               T_prec=p0[-1]\n",
        "               C=check_reduction(t_prec,t) \n",
        "               if C==True:     \n",
        "                  R_ij=[[T_prec,T]]  \n",
        "                  p0.pop()\n",
        "                  p1=top(p1)   \n",
        "                  R=R+R_ij\n",
        "                  print('reductions:', R)\n",
        "                  print('reduced stack:',column(p0+p1,0))\n",
        "                  R_stack=R_stack+[T]  \n",
        "               else:      \n",
        "                  Rc=find_critical(R_stack,T)\n",
        "                  if Rc==T:\n",
        "                     R_stack=[]\n",
        "                     break\n",
        "                  else:   \n",
        "                    print(t,'is a critical type')\n",
        "                    D=decide_critical(string,R,Rc,T)\n",
        "                    if D==True:\n",
        "                       A=amend_reduction(p0,R,R_stack, Rc, T)\n",
        "                       p0,R,R_stack=A[0],A[1],A[2]                       \n",
        "                       p1=top(p1)\n",
        "                       print('reduced stack:',column(p0+p1,0))\n",
        "                       print('reductions amended',R)\n",
        "                       \n",
        "                    else:\n",
        "                       print('ignore criticality')\n",
        "                       R_stack=[]\n",
        "                       break\n",
        "           else:\n",
        "               Rc=find_critical(R_stack,T)\n",
        "               if Rc==T:\n",
        "                     R_stack=[]\n",
        "                     break\n",
        "               else:   \n",
        "                    print(T, 'is a critical type') \n",
        "                    D=decide_critical(string,R,Rc,T)\n",
        "                    if D==True:\n",
        "                       A=amend_reduction(p0,R,R_stack, Rc, T)\n",
        "                       p0,R,R_stack=A[0],A[1],A[2]\n",
        "                       p1=top(p1)  \n",
        "                       print('reduced stack:',column(p0+p1,0))\n",
        "                       print('amended reductions:',R)\n",
        "                    else:\n",
        "                       print('ignore criticality')\n",
        "                       R_stack=[]\n",
        "                       break\n",
        "\n",
        "\n",
        "\n",
        "       p0=p0+p1         \n",
        "       print('reduced stack:',column(p0,0))\n",
        "       k=k+1\n",
        "\n",
        "     p=column(p0,0)\n",
        "     Test=test(p,['s^r'], ['s'])\n",
        "     print('Reductions:')\n",
        "     return R  \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Y7e3YVGMxc8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 688
        },
        "outputId": "73f82243-000d-4851-93f8-f1e5650bd35d"
      },
      "source": [
        "dict={'alice':{('n')}, 'loves':{('n^r', 's', 'n^l')}, 'bob':{('n')}, 'very':{('n^r','n^l')},'much':{('n','n')}}\n",
        "#dict can be ambiguous \n",
        "s= ['alice', 'loves', 'bob', 'very','much'] \n",
        "parse(dict,s)\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sentence: ['alice', 'loves', 'bob', 'very', 'much']\n",
            "grammatical types: [['n'], ['n^r', 's', 'n^l'], ['n'], ['n^r', 'n^l'], ['n', 'n']]\n",
            "parsing:\n",
            "processed string: alice\n",
            "reductions: []\n",
            "reduced stack ['n']\n",
            "processed string: ['alice', 'loves']\n",
            "processed type: ('n^r', 1, 0)\n",
            "reductions: [[('n', 0, 0), ('n^r', 1, 0)]]\n",
            "reduced stack: ['s', 'n^l']\n",
            "processed type: ('s', 1, 1)\n",
            "reduced stack: ['s', 'n^l']\n",
            "processed string: ['alice', 'loves', 'bob']\n",
            "processed type: ('n', 2, 0)\n",
            "reductions: [[('n', 0, 0), ('n^r', 1, 0)], [('n^l', 1, 2), ('n', 2, 0)]]\n",
            "reduced stack: ['s']\n",
            "reduced stack: ['s']\n",
            "processed string: ['alice', 'loves', 'bob', 'very']\n",
            "processed type: ('n^r', 3, 0)\n",
            "n^r is a critical type\n",
            "reduced stack: ['s', 'n^l', 'n^l']\n",
            "reductions amended [[('n', 0, 0), ('n^r', 1, 0)], [('n', 2, 0), ('n^r', 3, 0)]]\n",
            "processed type: ('n^l', 3, 1)\n",
            "reduced stack: ['s', 'n^l', 'n^l']\n",
            "processed string: ['alice', 'loves', 'bob', 'very', 'much']\n",
            "processed type: ('n', 4, 0)\n",
            "reductions: [[('n', 0, 0), ('n^r', 1, 0)], [('n', 2, 0), ('n^r', 3, 0)], [('n^l', 3, 1), ('n', 4, 0)]]\n",
            "reduced stack: ['s', 'n^l', 'n']\n",
            "processed type: ('n', 4, 1)\n",
            "reductions: [[('n', 0, 0), ('n^r', 1, 0)], [('n', 2, 0), ('n^r', 3, 0)], [('n^l', 3, 1), ('n', 4, 0)], [('n^l', 1, 2), ('n', 4, 1)]]\n",
            "reduced stack: ['s']\n",
            "reduced stack: ['s']\n",
            "parsed correctly to type ['s']\n",
            "Reductions:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[('n', 0, 0), ('n^r', 1, 0)],\n",
              " [('n', 2, 0), ('n^r', 3, 0)],\n",
              " [('n^l', 3, 1), ('n', 4, 0)],\n",
              " [('n^l', 1, 2), ('n', 4, 1)]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    }
  ]
}